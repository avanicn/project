{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bfd40102-af31-426d-a72f-c42dc8ef0e6d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"CICIDS2017_sample.csv\")\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d66857-da6b-4d20-bd0e-0edd645a0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the column names and number of missing values\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d6fe3-d596-4076-8423-bdd086593841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which columns might be all 0 or not helpful\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ef041-e46d-40ce-abe6-156fa7c03bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what labels or attack types we have\n",
    "df['Label'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb04b77-5d1b-4dbc-bc68-7fb50b27a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary: 0 for BENIGN, 1 for any attack\n",
    "df['Attack'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d20a08-c88c-4d2d-bd04-a400c4866d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric and unnecessary columns\n",
    "df = df.drop(['Label'], axis=1)\n",
    "\n",
    "# Drop any columns with non-numeric data (just in case)\n",
    "df = df.select_dtypes(include='number')\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop('Attack', axis=1)\n",
    "y = df['Attack']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46c5e5-6584-4501-aa7c-d75b24433756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Make sure y matches the updated X\n",
    "y = y[X.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2a9fd-c95b-45ab-97ee-cf789096979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# See results\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5311090-4d9f-455a-af2a-5893d111033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f6662-d0a4-4cb8-aedd-e6f45b337c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(scores)\n",
    "print(\"Average accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733d8d7-3f7c-497e-bd5c-8b4c26642dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364c3eb-398b-4273-8e2e-c674682d7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done. Report generated.\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc8420-b677-4376-a0e3-217ab5b9396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame (if not already)\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_test = pd.DataFrame(X_test)\n",
    "\n",
    "# Check for any overlap\n",
    "common = pd.merge(df_train, df_test, how='inner')\n",
    "print(f\"Number of duplicate rows between train and test: {len(common)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364f566-daf2-45e9-8942-97ae4629c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# STEP 1: Clean the full dataset FIRST\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Align target (in case some rows dropped from X)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# STEP 2: Now do the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5124b43-6735-4809-8f03-b184ee0beac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48936ca-5acd-4491-9c13-8cf7a9f0698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0001b8-28e9-4b7b-8ef3-3f93fdaea704",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique = X_train.drop_duplicates()\n",
    "test_unique = X_test[~X_test.apply(tuple, axis=1).isin(train_unique.apply(tuple, axis=1))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9da70-e402-4d7a-81e7-1c81d6267038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_clean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff0780-5fdd-481e-bad5-d4cd439620c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_clean = df.drop_duplicates()\n",
    "X = X_clean.drop('Attack', axis=1)\n",
    "y = X_clean['Attack']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d710377-3bf2-4ce0-a2a0-b239ab6ab5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8332e66-3803-463e-a649-0a996c473984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d95b1-4dfc-4e18-9df5-f5fe1e25b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates first\n",
    "X_clean = df.drop_duplicates()\n",
    "\n",
    "# Separate features and label (corrected column name)\n",
    "X = X_clean.drop('Attack', axis=1)\n",
    "y = X_clean['Attack']\n",
    "\n",
    "# Clean data: remove infinities and NaNs\n",
    "import numpy as np\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Align y with cleaned X\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Split into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3b5c9-49ea-4d83-ae6d-8425e8c6bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3346e0-1a5e-455f-a0c1-bb7e696c8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2425aa-4d75-4785-8792-2afab28582b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show precision, recall, F1-score, accuracy\n",
    "print(\"ðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Show confusion matrix\n",
    "print(\"ðŸ§® Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ca948-ed15-4920-a744-6f834adcf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=[\"Benign\", \"Attack\"], cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d0075-a6b2-4dd5-94b5-1e5714cf9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using your trained model\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fcbc9-bd41-4812-bdaf-15dee55929e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visual confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    display_labels=[\"Benign\", \"Attack\"],\n",
    "    cmap='Blues',\n",
    "    colorbar=True\n",
    ")\n",
    "\n",
    "# Add labels and display\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d9097-f740-461d-aa49-63266564cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47aa4e-cb08-4703-bb9e-8a4c11f81048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create explainer for your trained tree-based model (e.g. RandomForest)\n",
    "explainer = shap.TreeExplainer(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807a997-ecc8-4608-8deb-40f11d722e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a small slice of your test set to keep it fast\n",
    "X_sample = X_test[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1efd6-0770-4811-a5af-a9349686f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SHAP values for the sample\n",
    "shap_values = explainer.shap_values(X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae9f4e-b125-4620-898e-c1860223a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification, use shap_values[1] for the \"Attack\" class\n",
    "shap.summary_plot(shap_values[1], X_sample, plot_type=\"dot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdcf20-9e7b-4d5d-becb-60b3c7c447e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_sample shape:\", X_sample.shape)\n",
    "print(\"shap_values[1] shape:\", shap_values[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda2495-e7ff-4839-8a7f-312b0d5e4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose SHAP values to match shape (100, 77)\n",
    "shap_fixed = shap_values[1].T\n",
    "\n",
    "# Plot it!\n",
    "shap.summary_plot(shap_fixed, X_sample, plot_type=\"dot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3be09-42af-419b-8724-13cebfc598b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_sample shape:\", X_sample.shape)          # should be (100, 77)\n",
    "print(\"shap_values[1] shape:\", shap_values[1].shape)  # currently (77, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911553a-78f5-47fa-b314-df80b982c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the SHAP shape to match X_sample\n",
    "shap_fixed = shap_values[1].T  # makes it (2, 77)\n",
    "\n",
    "print(\"shap_fixed shape:\", shap_fixed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f984e-cb53-42c9-a92d-15c8f5101aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Use a tiny sample to keep SHAP fast and safe\n",
    "X_sample = X_test[:10]  # Keep it very small to avoid shape bugs\n",
    "\n",
    "# Recalculate SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# Print shape sanity check\n",
    "print(\"X_sample shape:\", X_sample.shape)\n",
    "print(\"shap_values[1] shape:\", shap_values[1].shape)\n",
    "\n",
    "# Should now match: (10, number of features)\n",
    "# Plot the summary\n",
    "shap.summary_plot(shap_values[1], X_sample, plot_type=\"dot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1351a2-a218-4ed8-b439-31ada440e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Use a small sample for speed\n",
    "X_sample = X_test[:10]\n",
    "\n",
    "# Use the new SHAP explainer that handles this stuff better\n",
    "explainer = shap.Explainer(model, X_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# Summary plot (will just work!)\n",
    "shap.summary_plot(shap_values, X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33910c7-51f3-4ca7-971b-b98572722827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Sample just 100 rows to speed up computation\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# SHAP for tree models\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# For binary classification: shap_values[1] is class \"Attack\"\n",
    "print(f\"SHAP values shape: {shap_values[1].shape}\")\n",
    "print(f\"X_sample shape: {X_sample.shape}\")\n",
    "\n",
    "# Plot the summary\n",
    "shap.summary_plot(shap_values[1], X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecfeb2-b454-46ae-b044-e90bb11b0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose from (features, classes) to (samples, features)\n",
    "# Assuming you're using something like a LinearExplainer or kernel-based model\n",
    "\n",
    "# Re-run SHAP value computation\n",
    "explainer = shap.Explainer(model, X_sample)  # Automatically selects right explainer\n",
    "shap_values = explainer(X_sample)  # NEW API returns an object with shap_values.values\n",
    "\n",
    "# Print shapes to debug\n",
    "print(\"SHAP values shape:\", shap_values.values.shape)  # Should be (100, 77)\n",
    "print(\"X_sample shape:\", X_sample.shape)\n",
    "\n",
    "# Plot with the new object (shap.Explanation)\n",
    "shap.summary_plot(shap_values[..., 1], X_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c733e91-ab49-4fd9-a272-5bd358577356",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[..., 1], X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b3ee00-a127-42a5-a1b1-c94e0f3c387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Benchmarking\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define models to benchmark\n",
    "models = {\n",
    "    \"Random Forest\": model,  # your trained RF model\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for name, clf in models.items():\n",
    "    # Skip retraining Random Forest\n",
    "    if name != \"Random Forest\":\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_bench = clf.predict(X_test)\n",
    "    print(f\"\\nðŸ“Š {name} Performance:\")\n",
    "    print(classification_report(y_test, y_pred_bench))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885bac67-c535-41e3-8462-ceb09cb2cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe34ce-c381-4fb1-b9d0-a00289eb0e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
